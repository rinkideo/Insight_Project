{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## Importing libraries for model Pipeline\n",
    "from sklearn.model_selection import train_test_split,KFold, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score,classification_report, confusion_matrix,precision_score,recall_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import plot_roc_curve,auc,roc_curve\n",
    "\n",
    "\n",
    "#import xgboost as xgb\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "#from sklearn.model_selection import GridSearchCV, cross_val_score, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('CSV2018Head1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data['AB_NICU']!='U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#field_sel1 = pd.read_csv('field_sel.csv')\n",
    "##['DOB_YY', 'DOB_MM', 'DOB_TT', 'DOB_WK']\n",
    "\n",
    "field_sel=['BFACIL', 'MAGER9',\n",
    "       'MBSTATE_REC', 'RESTATUS', 'MRACE6', 'MHISP_R', 'DMAR', 'F_MEDUC',\n",
    "       'FAGEREC11', 'FRACE6', 'FHISP_R', 'FEDUC', 'PRIORTERM', 'ILLB_R11',\n",
    "       'PRECARE5', 'PREVIS_REC', 'CIG0_R', 'CIG1_R', 'CIG2_R', 'CIG3_R',\n",
    "       'M_Ht_In', 'PWgt_R', 'WTGAIN_REC', 'RF_PDIAB', 'RF_GDIAB', 'RF_PHYPE',\n",
    "       'RF_GHYPE', 'RF_EHYPE', 'RF_PPTERM', 'RF_INFTR', 'RF_FEDRG', 'RF_ARTEC',\n",
    "       'RF_CESAR', 'RF_CESARN', 'MRACE6', 'MHISP_R', 'DMAR', 'F_MEDUC',\n",
    "       'FAGEREC11', 'FRACE6', 'FHISP_R', 'FEDUC', 'PRIORTERM',\n",
    "       'ILLB_R11', 'PRECARE5', 'PREVIS_REC', 'CIG0_R', 'CIG1_R',\n",
    "       'CIG2_R', 'CIG3_R', 'M_Ht_In', 'PWgt_R', 'WTGAIN_REC',\n",
    "       'RF_PDIAB', 'RF_GDIAB', 'RF_PHYPE', 'RF_GHYPE', 'RF_EHYPE',\n",
    "       'RF_PPTERM', 'RF_INFTR', 'RF_FEDRG', 'RF_ARTEC', 'RF_CESAR',\n",
    "       'RF_CESARN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BFACIL', 'MAGER9', 'MBSTATE_REC', 'RESTATUS', 'MRACE6', 'MHISP_R',\n",
       "       'DMAR', 'F_MEDUC', 'FAGEREC11', 'FRACE6', 'FHISP_R', 'FEDUC',\n",
       "       'PRIORTERM', 'ILLB_R11', 'PRECARE5', 'PREVIS_REC', 'CIG0_R', 'CIG1_R',\n",
       "       'CIG2_R', 'CIG3_R', 'M_Ht_In', 'PWgt_R', 'WTGAIN_REC', 'RF_PDIAB',\n",
       "       'RF_GDIAB', 'RF_PHYPE', 'RF_GHYPE', 'RF_EHYPE', 'RF_PPTERM', 'RF_INFTR',\n",
       "       'RF_FEDRG', 'RF_ARTEC', 'RF_CESAR', 'RF_CESARN', 'MRACE6', 'MHISP_R',\n",
       "       'DMAR', 'F_MEDUC', 'FAGEREC11', 'FRACE6', 'FHISP_R', 'FEDUC',\n",
       "       'PRIORTERM', 'ILLB_R11', 'PRECARE5', 'PREVIS_REC', 'CIG0_R', 'CIG1_R',\n",
       "       'CIG2_R', 'CIG3_R', 'M_Ht_In', 'PWgt_R', 'WTGAIN_REC', 'RF_PDIAB',\n",
       "       'RF_GDIAB', 'RF_PHYPE', 'RF_GHYPE', 'RF_EHYPE', 'RF_PPTERM', 'RF_INFTR',\n",
       "       'RF_FEDRG', 'RF_ARTEC', 'RF_CESAR', 'RF_CESARN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[field_sel]\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        N\n",
       "1        Y\n",
       "2        N\n",
       "3        N\n",
       "4        Y\n",
       "        ..\n",
       "19996    N\n",
       "19997    N\n",
       "19998    N\n",
       "19999    N\n",
       "20000    N\n",
       "Name: AB_NICU, Length: 19905, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_temp = df['AB_NICU']\n",
    "y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder() \n",
    "y1 = lb.fit_transform(y_temp)\n",
    "y=pd.Series(y1)\n",
    "y.name='AB_NICU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "19900    0\n",
       "19901    0\n",
       "19902    0\n",
       "19903    0\n",
       "19904    0\n",
       "Name: AB_NICU, Length: 19905, dtype: int32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19905 entries, 0 to 20000\n",
      "Data columns (total 64 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   BFACIL       19905 non-null  int64 \n",
      " 1   MAGER9       19905 non-null  int64 \n",
      " 2   MBSTATE_REC  19905 non-null  int64 \n",
      " 3   RESTATUS     19905 non-null  int64 \n",
      " 4   MRACE6       19905 non-null  int64 \n",
      " 5   MHISP_R      19905 non-null  int64 \n",
      " 6   DMAR         19905 non-null  int64 \n",
      " 7   F_MEDUC      19905 non-null  int64 \n",
      " 8   FAGEREC11    19905 non-null  int64 \n",
      " 9   FRACE6       19905 non-null  int64 \n",
      " 10  FHISP_R      19905 non-null  int64 \n",
      " 11  FEDUC        19905 non-null  int64 \n",
      " 12  PRIORTERM    19905 non-null  int64 \n",
      " 13  ILLB_R11     19905 non-null  int64 \n",
      " 14  PRECARE5     19905 non-null  int64 \n",
      " 15  PREVIS_REC   19905 non-null  int64 \n",
      " 16  CIG0_R       19905 non-null  int64 \n",
      " 17  CIG1_R       19905 non-null  int64 \n",
      " 18  CIG2_R       19905 non-null  int64 \n",
      " 19  CIG3_R       19905 non-null  int64 \n",
      " 20  M_Ht_In      19905 non-null  int64 \n",
      " 21  PWgt_R       19905 non-null  int64 \n",
      " 22  WTGAIN_REC   19905 non-null  int64 \n",
      " 23  RF_PDIAB     19905 non-null  object\n",
      " 24  RF_GDIAB     19905 non-null  object\n",
      " 25  RF_PHYPE     19905 non-null  object\n",
      " 26  RF_GHYPE     19905 non-null  object\n",
      " 27  RF_EHYPE     19905 non-null  object\n",
      " 28  RF_PPTERM    19905 non-null  object\n",
      " 29  RF_INFTR     19905 non-null  object\n",
      " 30  RF_FEDRG     19905 non-null  object\n",
      " 31  RF_ARTEC     19905 non-null  object\n",
      " 32  RF_CESAR     19905 non-null  object\n",
      " 33  RF_CESARN    19905 non-null  int64 \n",
      " 34  MRACE6       19905 non-null  int64 \n",
      " 35  MHISP_R      19905 non-null  int64 \n",
      " 36  DMAR         19905 non-null  int64 \n",
      " 37  F_MEDUC      19905 non-null  int64 \n",
      " 38  FAGEREC11    19905 non-null  int64 \n",
      " 39  FRACE6       19905 non-null  int64 \n",
      " 40  FHISP_R      19905 non-null  int64 \n",
      " 41  FEDUC        19905 non-null  int64 \n",
      " 42  PRIORTERM    19905 non-null  int64 \n",
      " 43  ILLB_R11     19905 non-null  int64 \n",
      " 44  PRECARE5     19905 non-null  int64 \n",
      " 45  PREVIS_REC   19905 non-null  int64 \n",
      " 46  CIG0_R       19905 non-null  int64 \n",
      " 47  CIG1_R       19905 non-null  int64 \n",
      " 48  CIG2_R       19905 non-null  int64 \n",
      " 49  CIG3_R       19905 non-null  int64 \n",
      " 50  M_Ht_In      19905 non-null  int64 \n",
      " 51  PWgt_R       19905 non-null  int64 \n",
      " 52  WTGAIN_REC   19905 non-null  int64 \n",
      " 53  RF_PDIAB     19905 non-null  object\n",
      " 54  RF_GDIAB     19905 non-null  object\n",
      " 55  RF_PHYPE     19905 non-null  object\n",
      " 56  RF_GHYPE     19905 non-null  object\n",
      " 57  RF_EHYPE     19905 non-null  object\n",
      " 58  RF_PPTERM    19905 non-null  object\n",
      " 59  RF_INFTR     19905 non-null  object\n",
      " 60  RF_FEDRG     19905 non-null  object\n",
      " 61  RF_ARTEC     19905 non-null  object\n",
      " 62  RF_CESAR     19905 non-null  object\n",
      " 63  RF_CESARN    19905 non-null  int64 \n",
      "dtypes: int64(44), object(20)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "20\n",
      "NUMERICAL_FEATURES: ['BFACIL', 'MAGER9', 'MBSTATE_REC', 'RESTATUS', 'MRACE6', 'MHISP_R', 'DMAR', 'F_MEDUC', 'FAGEREC11', 'FRACE6', 'FHISP_R', 'FEDUC', 'PRIORTERM', 'ILLB_R11', 'PRECARE5', 'PREVIS_REC', 'CIG0_R', 'CIG1_R', 'CIG2_R', 'CIG3_R', 'M_Ht_In', 'PWgt_R', 'WTGAIN_REC', 'RF_CESARN', 'MRACE6', 'MHISP_R', 'DMAR', 'F_MEDUC', 'FAGEREC11', 'FRACE6', 'FHISP_R', 'FEDUC', 'PRIORTERM', 'ILLB_R11', 'PRECARE5', 'PREVIS_REC', 'CIG0_R', 'CIG1_R', 'CIG2_R', 'CIG3_R', 'M_Ht_In', 'PWgt_R', 'WTGAIN_REC', 'RF_CESARN']\n",
      "CATEGORICAL_FEATURES: ['RF_PDIAB', 'RF_GDIAB', 'RF_PHYPE', 'RF_GHYPE', 'RF_EHYPE', 'RF_PPTERM', 'RF_INFTR', 'RF_FEDRG', 'RF_ARTEC', 'RF_CESAR', 'RF_PDIAB', 'RF_GDIAB', 'RF_PHYPE', 'RF_GHYPE', 'RF_EHYPE', 'RF_PPTERM', 'RF_INFTR', 'RF_FEDRG', 'RF_ARTEC', 'RF_CESAR']\n"
     ]
    }
   ],
   "source": [
    "# Numerical columns\n",
    "num_feat = X.select_dtypes(include='number').columns.to_list()\n",
    "\n",
    "# Categorical columns\n",
    "cat_feat = X.select_dtypes(include='object').columns.to_list()\n",
    "print(len(num_feat))\n",
    "print(len(cat_feat))\n",
    "print('NUMERICAL_FEATURES:',num_feat)\n",
    "print('CATEGORICAL_FEATURES:',cat_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    91.163024\n",
      "1     8.836976\n",
      "Name: AB_NICU, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y.value_counts(normalize=True)*100)\n",
    "sns.countplot(y)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('count')\n",
    "plt.title('Count of each target class')\n",
    "plt.grid(b= True, which='major', axis='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(missing_values =0, strategy ='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy ='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown= 'ignore'))\n",
    "    \n",
    "])\n",
    "\n",
    "ct = ColumnTransformer(remainder = 'drop',\n",
    "                      transformers=[\n",
    "                          ('numerical', num_pipe, num_feat),\n",
    "                          ('categorical', cat_pipe, cat_feat)\n",
    "                      ])\n",
    "\n",
    "##Logistic Regression\n",
    "model_1 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('logreg_classifier', LogisticRegression(solver = 'lbfgs',multi_class='auto'))   \n",
    "])\n",
    "\n",
    "\n",
    "## Decision Tree\n",
    "model_2 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('DT_classifier', DecisionTreeClassifier())   \n",
    "])\n",
    "\n",
    "## Random Forest\n",
    "model_3 = Pipeline([\n",
    "    ('ct', ct),\n",
    "    ('RF_classifier', RandomForestClassifier(n_jobs = -1))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdeo\\anaconda3\\envs\\insight_prj\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================== Test Results for: logreg_classifier \n",
      "====================================================================================\n",
      "In-sample f1 score: 0.08283233132932533\n",
      "Out-sample f1 score: 0.08808290155440415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      3620\n",
      "           1       0.68      0.05      0.09       361\n",
      "\n",
      "    accuracy                           0.91      3981\n",
      "   macro avg       0.80      0.52      0.52      3981\n",
      "weighted avg       0.89      0.91      0.88      3981\n",
      "\n",
      "confusion_matrix\n",
      "[[3612    8]\n",
      " [ 344   17]]\n",
      "=============================== Test Results for: DT_classifier \n",
      "====================================================================================\n",
      "In-sample f1 score: 0.9996422182468694\n",
      "Out-sample f1 score: 0.20565552699228792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      3620\n",
      "           1       0.19      0.22      0.21       361\n",
      "\n",
      "    accuracy                           0.84      3981\n",
      "   macro avg       0.56      0.56      0.56      3981\n",
      "weighted avg       0.86      0.84      0.85      3981\n",
      "\n",
      "confusion_matrix\n",
      "[[3283  337]\n",
      " [ 281   80]]\n",
      "=============================== Test Results for: RF_classifier \n",
      "====================================================================================\n",
      "In-sample f1 score: 0.9996422182468694\n",
      "Out-sample f1 score: 0.1646489104116223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      3620\n",
      "           1       0.65      0.09      0.16       361\n",
      "\n",
      "    accuracy                           0.91      3981\n",
      "   macro avg       0.79      0.54      0.56      3981\n",
      "weighted avg       0.89      0.91      0.88      3981\n",
      "\n",
      "confusion_matrix\n",
      "[[3602   18]\n",
      " [ 327   34]]\n",
      "=============================== END=============================\n"
     ]
    }
   ],
   "source": [
    "model_names = []\n",
    "f1_sc = []\n",
    "prec = []\n",
    "recall = []\n",
    "auc_val =[]\n",
    "\n",
    "\n",
    "for model in [model_1, model_2, model_3]:\n",
    "    model.fit(X_train, y_train)\n",
    "    print('=============================== Test Results for:','{} '.format(model.steps[1][0]))\n",
    "    print('====================================================================================')\n",
    "   \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print('In-sample f1 score:', f1_score(y_train, y_train_pred))\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print('Out-sample f1 score:',f1_score(y_test, y_test_pred))\n",
    "    \n",
    "    report = classification_report(y_test, y_test_pred)\n",
    "    print(report)\n",
    "\n",
    "    conf_mat=confusion_matrix(y_test, y_test_pred)\n",
    "    print('confusion_matrix')\n",
    "    print(conf_mat)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "    \n",
    "    \n",
    "    model_names.append(model.steps[1][0])\n",
    "    f1_sc.append(f1_score(y_test, y_test_pred))\n",
    "    prec.append(precision_score(y_test, y_test_pred))\n",
    "    recall.append(recall_score(y_test, y_test_pred))\n",
    "    auc_val.append(auc(fpr, tpr))\n",
    "    \n",
    "     \n",
    "    #print('TP:', conf_mat[1][1])\n",
    "   #print('TN:', conf_mat[0][0])\n",
    "   #print('FP:', conf_mat[0][1])\n",
    "   #print('FN:', conf_mat[1][0])\n",
    "\n",
    "   #classes = ['Not Fraud', 'Fraud']\n",
    "   #plot_confusion_matrix(model, X_test, y_test,display_labels = classes,cmap=plt.cm.Blues)\n",
    "   ###Normalization can be applied by setting `normalize='true', 'pred' 'all' or None.\n",
    "    \n",
    "    \n",
    "    #plot_precision_recall_curve(model,X_test,y_test)\n",
    "    \n",
    "    #plot_roc_curve(model,X_test,y_test)\n",
    "    \n",
    "print('=============================== END=============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prec_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logreg_classifier</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.047091</td>\n",
       "      <td>0.088083</td>\n",
       "      <td>0.522441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_classifier</th>\n",
       "      <td>0.191847</td>\n",
       "      <td>0.221607</td>\n",
       "      <td>0.205656</td>\n",
       "      <td>0.564256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_classifier</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.094183</td>\n",
       "      <td>0.164649</td>\n",
       "      <td>0.544605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   prec_score  recall_score  f1_score  auc_score\n",
       "logreg_classifier    0.680000      0.047091  0.088083   0.522441\n",
       "DT_classifier        0.191847      0.221607  0.205656   0.564256\n",
       "RF_classifier        0.653846      0.094183  0.164649   0.544605"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_df = pd.DataFrame(list(zip(prec, recall,f1_sc,auc_val)),\n",
    "                       index = model_names, \n",
    "                       columns =['prec_score', 'recall_score','f1_score', 'auc_score'])\n",
    "\n",
    "perf_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **high recall + high precision** : the class is perfectly handled by the model\n",
    " * **low recall + high precision** : the model canâ€™t detect the class well but is highly trustable when it does\n",
    " * **high recall + low precision** : the class is well detected but the model also include points of other classes in it\n",
    " * **low recall + low precision** : the class is poorly handled by the model\n",
    " \n",
    "In the present dataset FP is more acceptable than FN. So, ideally the model should minimize FN i.e we need to optimize our model for Sensitivity(HIGH RECALL VALUE IS DESIRED). \n",
    " \n",
    " Low precision indicates a high number of false positives. Model includes more FP.\n",
    " Low Recall means high number of false negatives. \n",
    "\n",
    "https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the Skewed Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As mentioned above the current dataset is highly skewed.In such extreme cases the ideal solution is to collect mre data.\n",
    "However, this solution is not always feasible and hence we need to go for some other course of action. The alternative way to handle such imbalanced data is the resampling technique\n",
    " * Undersampling(majority class)\n",
    " * Oversampling (minority class)\n",
    " * SMOTE(generating synthetic samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insight_prj",
   "language": "python",
   "name": "insight_prj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
